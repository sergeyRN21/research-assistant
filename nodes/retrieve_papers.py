# nodes/retrieve_papers.py
import arxiv
import re

def retrieve_papers(state):
    """
    –£–∑–µ–ª 1: –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ arXiv API.
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ pdf_url –≤–µ–¥—ë—Ç –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é (–±–µ–∑ v1/v2).
    
    –í—Ö–æ–¥: state["question"]
    –í—ã—Ö–æ–¥: state["papers"]
    """
    print("üîç –£–∑–µ–ª: –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π —á–µ—Ä–µ–∑ arXiv API...")
    
    question = state["question"]
    
    search = arxiv.Search(
        query=question,
        max_results=2,
        sort_by=arxiv.SortCriterion.Relevance
    )
    
    papers = []
    try:
        for result in search.results():
            # üîß –§–æ—Ä–º–∏—Ä—É–µ–º —á–∏—Å—Ç—ã–π URL –±–µ–∑ –≤–µ—Ä—Å–∏–∏
            base_id = result.entry_id.split("/")[-1].split("v")[0]
            # --- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π URL ---
            pdf_url = f"https://arxiv.org/pdf/{base_id}.pdf" # <- –£–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç (—Ç–µ–ø–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π)
            if not re.fullmatch(r"https://arxiv\.org/pdf/\d+\.\d+\.pdf", pdf_url):
                 print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL: {pdf_url}")
                 continue
                
            papers.append({
                "entry_id": result.entry_id,
                "title": result.title,
                "summary": result.summary,
                "pdf_url": pdf_url,
                "published": result.published.strftime("%Y-%m-%d"),
                "authors": [author.name for author in result.authors]
            })
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π: {e}")
        return {"papers": [], "error": str(e)}
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(papers)} —Å—Ç–∞—Ç–µ–π —Å PDF.")
    return {"papers": papers}