# nodes/generate_hypotheses.py
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
    model="google/gemini-2.0-flash-001",
    timeout=30,
    max_retries=2
)

def generate_hypotheses(state):
    """
    –£–∑–µ–ª 3: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ –≥–∏–ø–æ—Ç–µ–∑—ã –∏–∑ –≤–æ–ø—Ä–æ—Å–∞.
    –í—Ö–æ–¥ = state['question']
    –í—ã—Ö–æ–¥ = state['hypotheses']
    """
    print("üí° –£–∑–µ–ª: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑")

    question = state.get("question")
    
    return {"hypotheses": ["hypothetical hypothesis"]}