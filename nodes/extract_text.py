# nodes/extract_text.py
import requests
from pypdf import PdfReader
import io
import re

def extract_text(state):
    """
    –£–∑–µ–ª 2: –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF —Å—Ç–∞—Ç–µ–π.
    –°–∫–∞—á–∏–≤–∞–µ—Ç PDF –≤ –ø–∞–º—è—Ç—å, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –≤ –Ω—ë–º —Ä–µ–∞–ª—å–Ω—ã–π –Ω–∞—É—á–Ω—ã–π —Ç–µ–∫—Å—Ç.
    
    –í—Ö–æ–¥: state["papers"] (—Å–ø–∏—Å–æ–∫ —Å pdf_url)
    –í—ã—Ö–æ–¥: state["retrieved_texts"] (—Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ —Ç–µ–∫—Å—Ç–∞)
    """
    print("üìÑ –£–∑–µ–ª: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF...")
    
    papers = state.get("papers", [])
    if not papers:
        print("‚ö†Ô∏è –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.")
        return {"retrieved_texts": []}
    
    retrieved_texts = []
    for i, paper in enumerate(papers):
        pdf_url = paper.get("pdf_url")
        if not pdf_url:
            print(f"‚ö†Ô∏è –£ —Å—Ç–∞—Ç—å–∏ '{paper.get('title', 'Unknown')}' –Ω–µ—Ç PDF-—Å—Å—ã–ª–∫–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        print(f"üì• –°–∫–∞—á–∏–≤–∞–µ–º PDF [{i+1}/{len(papers)}]: {pdf_url}")
        try:
            response = requests.get(pdf_url, timeout=15)
            response.raise_for_status()

            pdf = PdfReader(io.BytesIO(response.content))
            full_text = ""
            for page in pdf.pages:
                full_text += page.extract_text() + "\n"
            
            # üî• –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç ‚Äî –Ω–µ —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            clean_text = re.sub(r'\s+', ' ', full_text).strip()
            
            # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã "–º—É—Å–æ—Ä–Ω–æ–≥–æ" PDF
            low_quality_indicators = [
                "IEEE" in clean_text[:500] and "grant" in clean_text[:800],
                "Personal use of this material is permitted" in clean_text,
                "This research was supported by" in clean_text,
                "¬©" in clean_text[:200] and "All rights reserved" in clean_text,
                len(clean_text) < 1000,
                "Abstract" not in clean_text[:500],  # –µ—Å–ª–∏ –Ω–µ—Ç Abstract ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ, –Ω–µ —Å—Ç–∞—Ç—å—è
            ]
            
            if any(low_quality_indicators):
                print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º PDF: —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
                retrieved_texts.append("")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–∞—É—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            scientific_keywords = ["method", "model", "experiment", "attention", "layer", "network", "dataset", "result"]
            if not any(kw in clean_text.lower() for kw in scientific_keywords):
                print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º PDF: –Ω–µ—Ç –Ω–∞—É—á–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è")
                retrieved_texts.append("")
                continue
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
            text = full_text[:10_000]  # –ø–µ—Ä–≤—ã–µ 10 000 —Å–∏–º–≤–æ–ª–æ–≤
            retrieved_texts.append(text)
            print(f"‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á—ë–Ω ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pdf_url}: {e}")
            retrieved_texts.append("")  # –¥–æ–±–∞–≤–∏–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ä—è–¥–æ–∫
    
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(retrieved_texts)}")
    
    return {"retrieved_texts": retrieved_texts}